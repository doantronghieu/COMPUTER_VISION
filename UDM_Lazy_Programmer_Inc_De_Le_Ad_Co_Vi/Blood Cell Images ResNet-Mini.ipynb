{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, BatchNormalization, ZeroPadding2D,\\\n",
    "    MaxPooling2D, add, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -nc https://lazyprogrammer.me/course_files/blood_cell_images.zip\n",
    "!unzip -nq blood_cell_images.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize all images to this\n",
    "IMAGE_SIZE = [224, 224]\n",
    "\n",
    "# Training config\n",
    "epochs     = 16\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'blood_cell_images/TRAIN'\n",
    "valid_path = 'blood_cell_images/TEST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful for getting number of files\n",
    "image_files       = glob(train_path + '/*/*.jp*g')\n",
    "valid_image_files = glob(valid_path + '/*/*.jp*g')\n",
    "# Useful for getting number of classes\n",
    "folders = glob(train_path + '/*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at an image for fun\n",
    "plt.imshow(image.load_img(np.random.choice(image_files)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_, kernel_size, filters):\n",
    "    # 03 filter sizes\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    x = Conv2D(filters=f1, kernel_size=(1, 1), kernel_initializer='he_normal')(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=f2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=f3, kernel_size=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = add([x, input_])\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_, kernel_size, filters, strides=(2, 2)):\n",
    "    f1, f2, f3 = filters\n",
    "    \n",
    "    x = Conv2D(filters=f1, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal')(input_)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=f2, kernel_size=kernel_size, padding='same', kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    x = Conv2D(filters=f3, kernel_size=(1, 1), kernel_initializer='he_normal')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=strides, kernel_initializer='he_normal')(input_)\n",
    "    shortcut = BatchNormalization()(shortcut)\n",
    "    \n",
    "    x = add([x, shortcut])\n",
    "    x = Activation(activation='relu')(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom ResNet\n",
    "i = Input(shape=IMAGE_SIZE + [3])\n",
    "x = ZeroPadding2D(padding=(3, 3))(i)\n",
    "x = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2), padding='valid', kernel_initializer='he_normal')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation(activation='relu')(x)\n",
    "\n",
    "x = ZeroPadding2D(padding=(1, 1))(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2))(x)\n",
    "\n",
    "x = conv_block    (input_=x, kernel_size=3, filters=[64, 64, 256], strides=(1, 1))\n",
    "x = identity_block(input_=x, kernel_size=3, filters=[64, 64, 256])\n",
    "x = identity_block(input_=x, kernel_size=3, filters=[64, 64, 256])\n",
    "\n",
    "x = conv_block    (input_=x, kernel_size=3, filters=[128, 128, 512])\n",
    "x = identity_block(input_=x, kernel_size=3, filters=[128, 128, 512])\n",
    "x = identity_block(input_=x, kernel_size=3, filters=[128, 128, 512])\n",
    "x = identity_block(input_=x, kernel_size=3, filters=[128, 128, 512])\n",
    "\n",
    "# The head of NN\n",
    "x = Flatten()(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "\n",
    "# A model object\n",
    "model = Model(inputs=i, outputs=prediction)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# The model's structure\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of ImageDataGenerator\n",
    "def preprocess_input2(x):\n",
    "    x /= 127.5\n",
    "    x -= 1.\n",
    "    return x\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1, \n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    preprocessing_function=preprocess_input2\n",
    ")\n",
    "val_gen = ImageDataGenerator(preprocessing_function=preprocess_input2)\n",
    "\n",
    "# Create generators\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    directory=train_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")\n",
    "valid_generator = val_gen.flow_from_directory(\n",
    "    directory=valid_path,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='sparse'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "checkpoint_filepath = '/tmp/checkpoint'\n",
    "r = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch= len(image_files)       // batch_size,\n",
    "    validation_steps=len(valid_image_files) // batch_size,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_filepath,\n",
    "            save_weights_only=True,\n",
    "            monitor='val_accuracy',\n",
    "            mode='max',\n",
    "            save_best_only=True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ee5cc6fef2d70a7e71ee3826687cbd150f18158e0b1eef11d4f4f92bb920e304"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
